# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing
from json.decoder import JSONDecodeError

from .....core.api_error import ApiError
from .....core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from .....core.datetime_utils import serialize_datetime
from .....core.http_response import AsyncHttpResponse, HttpResponse
from .....core.jsonable_encoder import jsonable_encoder
from .....core.pagination import AsyncPager, BaseHttpResponse, SyncPager
from .....core.request_options import RequestOptions
from .....core.unchecked_base_model import construct_type
from ...types.job import Job
from ...types.paginated_job_list import PaginatedJobList
from ...types.paginated_screening_question_list import PaginatedScreeningQuestionList
from ...types.screening_question import ScreeningQuestion
from .types.jobs_list_request_expand_item import JobsListRequestExpandItem
from .types.jobs_list_request_status import JobsListRequestStatus
from .types.jobs_retrieve_request_expand_item import JobsRetrieveRequestExpandItem
from .types.jobs_screening_questions_list_request_expand_item import JobsScreeningQuestionsListRequestExpandItem


class RawJobsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self,
        *,
        code: typing.Optional[str] = None,
        created_after: typing.Optional[dt.datetime] = None,
        created_before: typing.Optional[dt.datetime] = None,
        cursor: typing.Optional[str] = None,
        expand: typing.Optional[
            typing.Union[JobsListRequestExpandItem, typing.Sequence[JobsListRequestExpandItem]]
        ] = None,
        include_deleted_data: typing.Optional[bool] = None,
        include_remote_data: typing.Optional[bool] = None,
        include_shell_data: typing.Optional[bool] = None,
        modified_after: typing.Optional[dt.datetime] = None,
        modified_before: typing.Optional[dt.datetime] = None,
        offices: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        remote_fields: typing.Optional[typing.Literal["status"]] = None,
        remote_id: typing.Optional[str] = None,
        show_enum_origins: typing.Optional[typing.Literal["status"]] = None,
        status: typing.Optional[JobsListRequestStatus] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SyncPager[Job]:
        """
        Returns a list of `Job` objects.

        Parameters
        ----------
        code : typing.Optional[str]
            If provided, will only return jobs with this code.

        created_after : typing.Optional[dt.datetime]
            If provided, will only return objects created after this datetime.

        created_before : typing.Optional[dt.datetime]
            If provided, will only return objects created before this datetime.

        cursor : typing.Optional[str]
            The pagination cursor value.

        expand : typing.Optional[typing.Union[JobsListRequestExpandItem, typing.Sequence[JobsListRequestExpandItem]]]
            Which relations should be returned in expanded form. Multiple relation names should be comma separated without spaces.

        include_deleted_data : typing.Optional[bool]
            Indicates whether or not this object has been deleted in the third party platform. Full coverage deletion detection is a premium add-on. Native deletion detection is offered for free with limited coverage. [Learn more](https://docs.merge.dev/integrations/hris/supported-features/).

        include_remote_data : typing.Optional[bool]
            Whether to include the original data Merge fetched from the third-party to produce these models.

        include_shell_data : typing.Optional[bool]
            Whether to include shell records. Shell records are empty records (they may contain some metadata but all other fields are null).

        modified_after : typing.Optional[dt.datetime]
            If provided, only objects synced by Merge after this date time will be returned.

        modified_before : typing.Optional[dt.datetime]
            If provided, only objects synced by Merge before this date time will be returned.

        offices : typing.Optional[str]
            If provided, will only return jobs for this office; multiple offices can be separated by commas.

        page_size : typing.Optional[int]
            Number of results to return per page.

        remote_fields : typing.Optional[typing.Literal["status"]]
            Deprecated. Use show_enum_origins.

        remote_id : typing.Optional[str]
            The API provider's ID for the given object.

        show_enum_origins : typing.Optional[typing.Literal["status"]]
            A comma separated list of enum field names for which you'd like the original values to be returned, instead of Merge's normalized enum values. [Learn more](https://help.merge.dev/en/articles/8950958-show_enum_origins-query-parameter)

        status : typing.Optional[JobsListRequestStatus]
            If provided, will only return jobs with this status. Options: ('OPEN', 'CLOSED', 'DRAFT', 'ARCHIVED', 'PENDING')

            * `OPEN` - OPEN
            * `CLOSED` - CLOSED
            * `DRAFT` - DRAFT
            * `ARCHIVED` - ARCHIVED
            * `PENDING` - PENDING

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SyncPager[Job]

        """
        _response = self._client_wrapper.httpx_client.request(
            "ats/v1/jobs",
            base_url=self._client_wrapper.get_environment().api,
            method="GET",
            params={
                "code": code,
                "created_after": serialize_datetime(created_after) if created_after is not None else None,
                "created_before": serialize_datetime(created_before) if created_before is not None else None,
                "cursor": cursor,
                "expand": expand,
                "include_deleted_data": include_deleted_data,
                "include_remote_data": include_remote_data,
                "include_shell_data": include_shell_data,
                "modified_after": serialize_datetime(modified_after) if modified_after is not None else None,
                "modified_before": serialize_datetime(modified_before) if modified_before is not None else None,
                "offices": offices,
                "page_size": page_size,
                "remote_fields": remote_fields,
                "remote_id": remote_id,
                "show_enum_origins": show_enum_origins,
                "status": status,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _parsed_response = typing.cast(
                    PaginatedJobList,
                    construct_type(
                        type_=PaginatedJobList,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                _items = _parsed_response.results
                _parsed_next = _parsed_response.next
                _has_next = _parsed_next is not None and _parsed_next != ""
                _get_next = lambda: self.list(
                    code=code,
                    created_after=created_after,
                    created_before=created_before,
                    cursor=_parsed_next,
                    expand=expand,
                    include_deleted_data=include_deleted_data,
                    include_remote_data=include_remote_data,
                    include_shell_data=include_shell_data,
                    modified_after=modified_after,
                    modified_before=modified_before,
                    offices=offices,
                    page_size=page_size,
                    remote_fields=remote_fields,
                    remote_id=remote_id,
                    show_enum_origins=show_enum_origins,
                    status=status,
                    request_options=request_options,
                )
                return SyncPager(
                    has_next=_has_next, items=_items, get_next=_get_next, response=BaseHttpResponse(response=_response)
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def retrieve(
        self,
        id: str,
        *,
        expand: typing.Optional[
            typing.Union[JobsRetrieveRequestExpandItem, typing.Sequence[JobsRetrieveRequestExpandItem]]
        ] = None,
        include_remote_data: typing.Optional[bool] = None,
        include_shell_data: typing.Optional[bool] = None,
        remote_fields: typing.Optional[typing.Literal["status"]] = None,
        show_enum_origins: typing.Optional[typing.Literal["status"]] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[Job]:
        """
        Returns a `Job` object with the given `id`.

        Parameters
        ----------
        id : str

        expand : typing.Optional[typing.Union[JobsRetrieveRequestExpandItem, typing.Sequence[JobsRetrieveRequestExpandItem]]]
            Which relations should be returned in expanded form. Multiple relation names should be comma separated without spaces.

        include_remote_data : typing.Optional[bool]
            Whether to include the original data Merge fetched from the third-party to produce these models.

        include_shell_data : typing.Optional[bool]
            Whether to include shell records. Shell records are empty records (they may contain some metadata but all other fields are null).

        remote_fields : typing.Optional[typing.Literal["status"]]
            Deprecated. Use show_enum_origins.

        show_enum_origins : typing.Optional[typing.Literal["status"]]
            A comma separated list of enum field names for which you'd like the original values to be returned, instead of Merge's normalized enum values. [Learn more](https://help.merge.dev/en/articles/8950958-show_enum_origins-query-parameter)

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[Job]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"ats/v1/jobs/{jsonable_encoder(id)}",
            base_url=self._client_wrapper.get_environment().api,
            method="GET",
            params={
                "expand": expand,
                "include_remote_data": include_remote_data,
                "include_shell_data": include_shell_data,
                "remote_fields": remote_fields,
                "show_enum_origins": show_enum_origins,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Job,
                    construct_type(
                        type_=Job,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def screening_questions_list(
        self,
        job_id: str,
        *,
        cursor: typing.Optional[str] = None,
        expand: typing.Optional[
            typing.Union[
                JobsScreeningQuestionsListRequestExpandItem,
                typing.Sequence[JobsScreeningQuestionsListRequestExpandItem],
            ]
        ] = None,
        include_deleted_data: typing.Optional[bool] = None,
        include_remote_data: typing.Optional[bool] = None,
        include_shell_data: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SyncPager[ScreeningQuestion]:
        """
        Returns a list of `ScreeningQuestion` objects.

        Parameters
        ----------
        job_id : str

        cursor : typing.Optional[str]
            The pagination cursor value.

        expand : typing.Optional[typing.Union[JobsScreeningQuestionsListRequestExpandItem, typing.Sequence[JobsScreeningQuestionsListRequestExpandItem]]]
            Which relations should be returned in expanded form. Multiple relation names should be comma separated without spaces.

        include_deleted_data : typing.Optional[bool]
            Indicates whether or not this object has been deleted in the third party platform. Full coverage deletion detection is a premium add-on. Native deletion detection is offered for free with limited coverage. [Learn more](https://docs.merge.dev/integrations/hris/supported-features/).

        include_remote_data : typing.Optional[bool]
            Whether to include the original data Merge fetched from the third-party to produce these models.

        include_shell_data : typing.Optional[bool]
            Whether to include shell records. Shell records are empty records (they may contain some metadata but all other fields are null).

        page_size : typing.Optional[int]
            Number of results to return per page.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SyncPager[ScreeningQuestion]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"ats/v1/jobs/{jsonable_encoder(job_id)}/screening-questions",
            base_url=self._client_wrapper.get_environment().api,
            method="GET",
            params={
                "cursor": cursor,
                "expand": expand,
                "include_deleted_data": include_deleted_data,
                "include_remote_data": include_remote_data,
                "include_shell_data": include_shell_data,
                "page_size": page_size,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _parsed_response = typing.cast(
                    PaginatedScreeningQuestionList,
                    construct_type(
                        type_=PaginatedScreeningQuestionList,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                _items = _parsed_response.results
                _parsed_next = _parsed_response.next
                _has_next = _parsed_next is not None and _parsed_next != ""
                _get_next = lambda: self.screening_questions_list(
                    job_id,
                    cursor=_parsed_next,
                    expand=expand,
                    include_deleted_data=include_deleted_data,
                    include_remote_data=include_remote_data,
                    include_shell_data=include_shell_data,
                    page_size=page_size,
                    request_options=request_options,
                )
                return SyncPager(
                    has_next=_has_next, items=_items, get_next=_get_next, response=BaseHttpResponse(response=_response)
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)


class AsyncRawJobsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self,
        *,
        code: typing.Optional[str] = None,
        created_after: typing.Optional[dt.datetime] = None,
        created_before: typing.Optional[dt.datetime] = None,
        cursor: typing.Optional[str] = None,
        expand: typing.Optional[
            typing.Union[JobsListRequestExpandItem, typing.Sequence[JobsListRequestExpandItem]]
        ] = None,
        include_deleted_data: typing.Optional[bool] = None,
        include_remote_data: typing.Optional[bool] = None,
        include_shell_data: typing.Optional[bool] = None,
        modified_after: typing.Optional[dt.datetime] = None,
        modified_before: typing.Optional[dt.datetime] = None,
        offices: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        remote_fields: typing.Optional[typing.Literal["status"]] = None,
        remote_id: typing.Optional[str] = None,
        show_enum_origins: typing.Optional[typing.Literal["status"]] = None,
        status: typing.Optional[JobsListRequestStatus] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncPager[Job]:
        """
        Returns a list of `Job` objects.

        Parameters
        ----------
        code : typing.Optional[str]
            If provided, will only return jobs with this code.

        created_after : typing.Optional[dt.datetime]
            If provided, will only return objects created after this datetime.

        created_before : typing.Optional[dt.datetime]
            If provided, will only return objects created before this datetime.

        cursor : typing.Optional[str]
            The pagination cursor value.

        expand : typing.Optional[typing.Union[JobsListRequestExpandItem, typing.Sequence[JobsListRequestExpandItem]]]
            Which relations should be returned in expanded form. Multiple relation names should be comma separated without spaces.

        include_deleted_data : typing.Optional[bool]
            Indicates whether or not this object has been deleted in the third party platform. Full coverage deletion detection is a premium add-on. Native deletion detection is offered for free with limited coverage. [Learn more](https://docs.merge.dev/integrations/hris/supported-features/).

        include_remote_data : typing.Optional[bool]
            Whether to include the original data Merge fetched from the third-party to produce these models.

        include_shell_data : typing.Optional[bool]
            Whether to include shell records. Shell records are empty records (they may contain some metadata but all other fields are null).

        modified_after : typing.Optional[dt.datetime]
            If provided, only objects synced by Merge after this date time will be returned.

        modified_before : typing.Optional[dt.datetime]
            If provided, only objects synced by Merge before this date time will be returned.

        offices : typing.Optional[str]
            If provided, will only return jobs for this office; multiple offices can be separated by commas.

        page_size : typing.Optional[int]
            Number of results to return per page.

        remote_fields : typing.Optional[typing.Literal["status"]]
            Deprecated. Use show_enum_origins.

        remote_id : typing.Optional[str]
            The API provider's ID for the given object.

        show_enum_origins : typing.Optional[typing.Literal["status"]]
            A comma separated list of enum field names for which you'd like the original values to be returned, instead of Merge's normalized enum values. [Learn more](https://help.merge.dev/en/articles/8950958-show_enum_origins-query-parameter)

        status : typing.Optional[JobsListRequestStatus]
            If provided, will only return jobs with this status. Options: ('OPEN', 'CLOSED', 'DRAFT', 'ARCHIVED', 'PENDING')

            * `OPEN` - OPEN
            * `CLOSED` - CLOSED
            * `DRAFT` - DRAFT
            * `ARCHIVED` - ARCHIVED
            * `PENDING` - PENDING

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncPager[Job]

        """
        _response = await self._client_wrapper.httpx_client.request(
            "ats/v1/jobs",
            base_url=self._client_wrapper.get_environment().api,
            method="GET",
            params={
                "code": code,
                "created_after": serialize_datetime(created_after) if created_after is not None else None,
                "created_before": serialize_datetime(created_before) if created_before is not None else None,
                "cursor": cursor,
                "expand": expand,
                "include_deleted_data": include_deleted_data,
                "include_remote_data": include_remote_data,
                "include_shell_data": include_shell_data,
                "modified_after": serialize_datetime(modified_after) if modified_after is not None else None,
                "modified_before": serialize_datetime(modified_before) if modified_before is not None else None,
                "offices": offices,
                "page_size": page_size,
                "remote_fields": remote_fields,
                "remote_id": remote_id,
                "show_enum_origins": show_enum_origins,
                "status": status,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _parsed_response = typing.cast(
                    PaginatedJobList,
                    construct_type(
                        type_=PaginatedJobList,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                _items = _parsed_response.results
                _parsed_next = _parsed_response.next
                _has_next = _parsed_next is not None and _parsed_next != ""

                async def _get_next():
                    return await self.list(
                        code=code,
                        created_after=created_after,
                        created_before=created_before,
                        cursor=_parsed_next,
                        expand=expand,
                        include_deleted_data=include_deleted_data,
                        include_remote_data=include_remote_data,
                        include_shell_data=include_shell_data,
                        modified_after=modified_after,
                        modified_before=modified_before,
                        offices=offices,
                        page_size=page_size,
                        remote_fields=remote_fields,
                        remote_id=remote_id,
                        show_enum_origins=show_enum_origins,
                        status=status,
                        request_options=request_options,
                    )

                return AsyncPager(
                    has_next=_has_next, items=_items, get_next=_get_next, response=BaseHttpResponse(response=_response)
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def retrieve(
        self,
        id: str,
        *,
        expand: typing.Optional[
            typing.Union[JobsRetrieveRequestExpandItem, typing.Sequence[JobsRetrieveRequestExpandItem]]
        ] = None,
        include_remote_data: typing.Optional[bool] = None,
        include_shell_data: typing.Optional[bool] = None,
        remote_fields: typing.Optional[typing.Literal["status"]] = None,
        show_enum_origins: typing.Optional[typing.Literal["status"]] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[Job]:
        """
        Returns a `Job` object with the given `id`.

        Parameters
        ----------
        id : str

        expand : typing.Optional[typing.Union[JobsRetrieveRequestExpandItem, typing.Sequence[JobsRetrieveRequestExpandItem]]]
            Which relations should be returned in expanded form. Multiple relation names should be comma separated without spaces.

        include_remote_data : typing.Optional[bool]
            Whether to include the original data Merge fetched from the third-party to produce these models.

        include_shell_data : typing.Optional[bool]
            Whether to include shell records. Shell records are empty records (they may contain some metadata but all other fields are null).

        remote_fields : typing.Optional[typing.Literal["status"]]
            Deprecated. Use show_enum_origins.

        show_enum_origins : typing.Optional[typing.Literal["status"]]
            A comma separated list of enum field names for which you'd like the original values to be returned, instead of Merge's normalized enum values. [Learn more](https://help.merge.dev/en/articles/8950958-show_enum_origins-query-parameter)

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[Job]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"ats/v1/jobs/{jsonable_encoder(id)}",
            base_url=self._client_wrapper.get_environment().api,
            method="GET",
            params={
                "expand": expand,
                "include_remote_data": include_remote_data,
                "include_shell_data": include_shell_data,
                "remote_fields": remote_fields,
                "show_enum_origins": show_enum_origins,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Job,
                    construct_type(
                        type_=Job,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def screening_questions_list(
        self,
        job_id: str,
        *,
        cursor: typing.Optional[str] = None,
        expand: typing.Optional[
            typing.Union[
                JobsScreeningQuestionsListRequestExpandItem,
                typing.Sequence[JobsScreeningQuestionsListRequestExpandItem],
            ]
        ] = None,
        include_deleted_data: typing.Optional[bool] = None,
        include_remote_data: typing.Optional[bool] = None,
        include_shell_data: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncPager[ScreeningQuestion]:
        """
        Returns a list of `ScreeningQuestion` objects.

        Parameters
        ----------
        job_id : str

        cursor : typing.Optional[str]
            The pagination cursor value.

        expand : typing.Optional[typing.Union[JobsScreeningQuestionsListRequestExpandItem, typing.Sequence[JobsScreeningQuestionsListRequestExpandItem]]]
            Which relations should be returned in expanded form. Multiple relation names should be comma separated without spaces.

        include_deleted_data : typing.Optional[bool]
            Indicates whether or not this object has been deleted in the third party platform. Full coverage deletion detection is a premium add-on. Native deletion detection is offered for free with limited coverage. [Learn more](https://docs.merge.dev/integrations/hris/supported-features/).

        include_remote_data : typing.Optional[bool]
            Whether to include the original data Merge fetched from the third-party to produce these models.

        include_shell_data : typing.Optional[bool]
            Whether to include shell records. Shell records are empty records (they may contain some metadata but all other fields are null).

        page_size : typing.Optional[int]
            Number of results to return per page.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncPager[ScreeningQuestion]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"ats/v1/jobs/{jsonable_encoder(job_id)}/screening-questions",
            base_url=self._client_wrapper.get_environment().api,
            method="GET",
            params={
                "cursor": cursor,
                "expand": expand,
                "include_deleted_data": include_deleted_data,
                "include_remote_data": include_remote_data,
                "include_shell_data": include_shell_data,
                "page_size": page_size,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _parsed_response = typing.cast(
                    PaginatedScreeningQuestionList,
                    construct_type(
                        type_=PaginatedScreeningQuestionList,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                _items = _parsed_response.results
                _parsed_next = _parsed_response.next
                _has_next = _parsed_next is not None and _parsed_next != ""

                async def _get_next():
                    return await self.screening_questions_list(
                        job_id,
                        cursor=_parsed_next,
                        expand=expand,
                        include_deleted_data=include_deleted_data,
                        include_remote_data=include_remote_data,
                        include_shell_data=include_shell_data,
                        page_size=page_size,
                        request_options=request_options,
                    )

                return AsyncPager(
                    has_next=_has_next, items=_items, get_next=_get_next, response=BaseHttpResponse(response=_response)
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)
